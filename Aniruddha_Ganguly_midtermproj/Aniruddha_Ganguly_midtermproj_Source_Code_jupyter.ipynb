{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "varying-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-petroleum",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dental-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(location):\n",
    "    \"\"\"\n",
    "    This function reads the data from the excel file.\n",
    "    The excel file should have two tabs named below:\n",
    "    1. Items\n",
    "    2. Transactions\n",
    "    The function reads the data without the header and assigns header to the dataframe afterwards.\n",
    "    To run the program with a new set of data, please create an .xlsx file with two above mentioned tabs and please do not\n",
    "    put header in the data as teh function automatically assigns header to avoid errors and naming conventions\n",
    "    Returns :\n",
    "    1. Pandas DataFrame (columns :[\"Item#\",\"ItemName\"])\n",
    "    1. Pandas DataFrame (columns :  [\"Transaction ID\",\"Transaction\"])\n",
    "    \"\"\"\n",
    "    items = pd.read_excel(location, sheet_name = \"Items\", header=None,names = [\"Item#\",\"ItemName\"])\n",
    "    # print (items.columns)\n",
    "    transactions = pd.read_excel(location, sheet_name = \"Transactions\", header=None,names = [\"Transaction ID\",\"Transaction\"])\n",
    "    # print (transactions.columns)\n",
    "    print (\"total number of distinct items : \",len(items.index))\n",
    "    print (\"total number of transactions : \", len(transactions.index))\n",
    "    return items,transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-light",
   "metadata": {},
   "source": [
    "## Calculate Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "civil-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_support(transaction,item):\n",
    "    \"\"\"\n",
    "    This function reads the data from the excel file.\n",
    "    The excel file should have two tabs named below:\n",
    "    1. Items\n",
    "    2. Transactions\n",
    "    The function reads the data without the header and assigns header to the dataframe afterwards.\n",
    "    To run the program with a new set of data, please create an .xlsx file with two above mentioned tabs and please do not\n",
    "    put header in the data as teh function automatically assigns header to avoid errors and naming conventions\n",
    "    Returns :\n",
    "    1. Pandas DataFrame (columns :[\"Item#\",\"ItemName\"])\n",
    "    1. Pandas DataFrame (columns :  [\"Transaction ID\",\"Transaction\"])\n",
    "    \"\"\"\n",
    "    Total_transactions = len(transaction.index)\n",
    "    item_temp = item\n",
    "    item_temp[\"Support\"] = 0.0\n",
    "    item_temp.Support = item_temp.Support.astype(float)\n",
    "    for i in item_temp.index:\n",
    "        item_list = item_temp.ItemName[i].split(\",\")\n",
    "        # print (len(item_list),item_list)\n",
    "        supp = 0\n",
    "        for j in transaction.index:\n",
    "            # print (transaction.Transaction[j].split(\",\"))\n",
    "            if all(x in map(str.strip,transaction.Transaction[j].split(\",\")) for x in item_list):\n",
    "                supp = supp + 1\n",
    "        item_temp.loc[i,\"Support\"] = float(supp)/Total_transactions\n",
    "    return item_temp.sort_values(by='Support',ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-yesterday",
   "metadata": {},
   "source": [
    "## Exclude by minimum support (min_support : User Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "multiple-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclusion_process(items,transactions,min_support):\n",
    "    \"\"\"\n",
    "    :param items: Pandas DataFrame (columns :[\"Item#\",\"ItemName\"]) | Source function : read_data()\n",
    "    :param transactions: Pandas DataFrame (columns :  [\"Transaction ID\",\"Transaction\"]) | Source function : read_data()\n",
    "    :param min_support: Minimum Support ( Provided by the User while running )\n",
    "    :return: Two Pandas DataFrame.\n",
    "             1. low_freq_combi --> Combinations of Items which has Support below min_support\n",
    "             2. high_frequent_combi --> Combinations of Items which has Support above min_support\n",
    "    \"\"\"\n",
    "    k = 1\n",
    "    low_freq_combi = []\n",
    "    high_frequent_combi = pd.DataFrame(columns=[\"ItemName\",\"Support\"])\n",
    "    distinct_items = list(set(items.ItemName))\n",
    "    # print (distinct_items)\n",
    "\n",
    "    while k < len(distinct_items):\n",
    "        k_freq_df = pd.DataFrame(columns=[\"ItemName\",\"Support\"])\n",
    "        k_freq_df[\"ItemName\"] = [\",\".join(i) for i in itertools.combinations(list(items.ItemName), k)]\n",
    "        support_df = calculate_support(transactions, k_freq_df)\n",
    "        # print (support_df)\n",
    "        low_freq_df = support_df[support_df.Support < min_support]\n",
    "        low_freq_df = low_freq_df.reset_index()\n",
    "        for lf in low_freq_df.index:\n",
    "            low_freq_combi.append(low_freq_df.ItemName[lf])\n",
    "\n",
    "        support_df = support_df[support_df.Support >= min_support]\n",
    "\n",
    "        for s in support_df.index:\n",
    "            l = len(high_frequent_combi.index)\n",
    "            high_frequent_combi.loc[l, \"ItemName\"] = support_df.ItemName[s]\n",
    "            high_frequent_combi.loc[l, \"Support\"] = support_df.Support[s]\n",
    "        k = k+1\n",
    "    return low_freq_combi,high_frequent_combi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-basin",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "intimate-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning(low_freq_combination,high_frequent_combination):\n",
    "    \"\"\"\n",
    "    :param low_freq_combination: Pandas DataFrame ( source : exclusion_process() )\n",
    "    :param high_frequent_combination: Pandas DataFrame ( source : exclusion_process() )\n",
    "    :return: Pandas DataFrame returns Pruned High Frequent Combination on the basis of\n",
    "            \"superset of low Support items\n",
    "             would also have low Support\"\n",
    "    \"\"\"\n",
    "    for i in low_freq_combination:\n",
    "        i = i.split(\",\")\n",
    "        for j in high_frequent_combination.index:\n",
    "            if all(x in map(str.strip, high_frequent_combination.ItemName[j].split(\",\")) for x in i):\n",
    "                high_frequent_combination = high_frequent_combination.drop(j)\n",
    "                high_frequent_combination = high_frequent_combination.reset_index(drop=True)\n",
    "    return high_frequent_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-harassment",
   "metadata": {},
   "source": [
    "## Calculate Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "prescribed-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence(A,B,support_df):\n",
    "    \"\"\"\n",
    "    This function calculates the confidence of any given two sets with their support\n",
    "                    Confidence(X,Y) = Support(X,Y)/Support(X)\n",
    "    :return:\n",
    "             printable_A --> Returns a string. Returns a string with '&' separator If there is multiple items\n",
    "             printable_B --> Returns a string. Returns a string with '&' separator If there is multiple items\n",
    "             support_ab --> Support of A,B\n",
    "             confidence --> Calculated confidence\n",
    "    \"\"\"\n",
    "    printable_A = \" & \".join(str(x) for x in sorted(list(A)))\n",
    "    printable_B = \" & \".join(str(x) for x in sorted(list(B)))\n",
    "    A_str = \",\".join(str(x) for x in sorted(list(A)))\n",
    "    AB_str = \",\".join(str(x) for x in sorted(list(A) + list(B)))\n",
    "    support_df[\"ItemName\"] = [\",\".join(y for y in sorted(list(x))) for x in support_df.item_list]\n",
    "    '''\n",
    "    print (support_df)\n",
    "    print (A_str)\n",
    "    print (B_str)\n",
    "    '''\n",
    "    support_a = support_df[support_df.ItemName == A_str].Support.values[0]\n",
    "    support_ab = support_df[support_df.ItemName == AB_str].Support.values[0]\n",
    "\n",
    "    confidence = float(support_ab) / support_a\n",
    "    return printable_A,printable_B,support_ab,confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-triumph",
   "metadata": {},
   "source": [
    "## Generate & Save Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "supreme-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_association_rules(pruned_frequent_items, min_confidence):\n",
    "    \"\"\"\n",
    "    :param pruned_frequent_items: Pandas DataFrame of pruned items who has support more than min_support (source : pruning())\n",
    "    :return: Pandas DataFrame with all the Rules,Support and Confidence for all the possible permutations\n",
    "    \"\"\"\n",
    "    Association_Rules = pd.DataFrame(columns=[\"Association_Rules\",\"Support(%)\",\"Confidence(%)\"])\n",
    "    pruned_frequent_items[\"item_list\"] = [x.split(\",\") for x in pruned_frequent_items[\"ItemName\"]]\n",
    "    pruned_frequent_items[\"item_length\"] = [len(x) for x in pruned_frequent_items[\"item_list\"]]\n",
    "    eligible_combinations = pruned_frequent_items[pruned_frequent_items.item_length > 1]\n",
    "    # print (eligible_combinations)\n",
    "\n",
    "    for i in eligible_combinations.index:\n",
    "        for p in list(itertools.permutations(eligible_combinations.item_list[i])):\n",
    "            for n in range(1,len(p)):\n",
    "                rule_str_left,rule_str_right,support,confidence = calculate_confidence(list(p[:-n]), p[-n:], pruned_frequent_items)\n",
    "                # print (rule_str_left,\"-->\",rule_str_right,\" | Support: \",support * 100,\"%\",\" Confidence: \",confidence * 100, \"%\")\n",
    "                Association_Rules.loc[-1] = [rule_str_left + \" --> \" + rule_str_right,support*100,confidence*100]\n",
    "                Association_Rules.index = Association_Rules.index + 1\n",
    "                Association_Rules = Association_Rules.sort_index()\n",
    "    Association_Rules = Association_Rules.drop_duplicates()\n",
    "    Association_Rules = Association_Rules.reset_index(drop = True)\n",
    "    Association_Rules = Association_Rules.sort_index(ascending=False)\n",
    "    Association_Rules = Association_Rules.reset_index(drop = True)\n",
    "    Association_Rules = Association_Rules[Association_Rules[\"Confidence(%)\"] >= min_confidence * 100]\n",
    "    Association_Rules.to_csv(os.getcwd() + \"/output/Association_Rules_\")\n",
    "    return Association_Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-biography",
   "metadata": {},
   "source": [
    "## Run Apriori (Wrapper Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "located-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Apriori(items, transactions, min_support, min_cofidence):\n",
    "    low_freq_combi, high_frequent_combi = exclusion_process(items, transactions, min_support)\n",
    "    # print (high_frequent_combi)\n",
    "    high_frequent_combi = pruning(low_freq_combi, high_frequent_combi)\n",
    "    association_rules = generate_association_rules(high_frequent_combi,min_cofidence)\n",
    "    #print (association_rules)\n",
    "    return association_rules.head(len(association_rules.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-mainstream",
   "metadata": {},
   "source": [
    "## Please Run the below code block everytime to run Apriori Algorithm and Generate Rules for Any given Dataset and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "geological-browser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------PARAMETERS-------------------\n",
      "\n",
      "Enter the Database Name from the following list \n",
      "--DATABASE_1_AMAZON.xlsx\n",
      "--DATABASE_4_NIKE.xlsx\n",
      "--Modified_Generic_Data_Canvas.xlsx\n",
      "--Generic_Data_Canvas.xlsx\n",
      "--DATABASE_3_KMART.xlsx\n",
      "--Homework_1_Apriori.xlsx\n",
      "--DATABASE_2_BESTBUY.xlsx\n",
      "\n",
      "File Name: DATABASE_1_AMAZON.xlsx\n",
      "Enter a minimum support value: 0.50\n",
      "Enter a minimum confidence value: 0.70\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------Association Rules-------------------\n",
      "\n",
      "total number of distinct items :  10\n",
      "total number of transactions :  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Association_Rules</th>\n",
       "      <th>Support(%)</th>\n",
       "      <th>Confidence(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Java: The Complete Reference --&gt; Java For Dummies</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java For Dummies --&gt; Java: The Complete Reference</td>\n",
       "      <td>50.0</td>\n",
       "      <td>76.923077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Association_Rules  Support(%)  \\\n",
       "0  Java: The Complete Reference --> Java For Dummies        50.0   \n",
       "1  Java For Dummies --> Java: The Complete Reference        50.0   \n",
       "\n",
       "   Confidence(%)  \n",
       "0     100.000000  \n",
       "1      76.923077  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_location = os.getcwd() + \"/input/\"\n",
    "all_files_available = [f for f in os.listdir(input_location) if os.path.isfile(os.path.join(input_location, f))]\n",
    "all_xlsx_inputs_available = [x for x in all_files_available if x[-5:] == '.xlsx']\n",
    "print (\"\\n-------------------PARAMETERS-------------------\\n\")\n",
    "location = input_location + str(input(\"Enter the Database Name from the following list \\n\" + ''.join(['--'+x+'\\n' for x in all_xlsx_inputs_available]) + \"\\nFile Name: \"))\n",
    "min_support = float(input(\"Enter a minimum support value: \"))\n",
    "min_confidence = float(input(\"Enter a minimum confidence value: \"))\n",
    "print (\"\\n-------------------------------------------------\\n\")\n",
    "print (\"\\n-------------------Association Rules-------------------\\n\")\n",
    "items, transactions = read_data(location)\n",
    "run_Apriori(items, transactions, min_support, min_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-reduction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
